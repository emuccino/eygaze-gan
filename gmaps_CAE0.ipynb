{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17576717111085461193\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import win_unicode_console\n",
    "from skimage import color\n",
    "from functools import partial\n",
    "import urllib.request\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_image_paris():\n",
    "    lat = \"%.6f\" % round((random.random() * .03) + 48.84, 6)\n",
    "    lon = \"%.6f\" % round((random.random() *.15) + 2.3, 6)\n",
    "    loc = str(lat) + ',' + str(lon)\n",
    "\n",
    "    head = str(random.random() *360)\n",
    "    url = r'https://maps.googleapis.com/maps/api/streetview/metadata?size=600x300&location='+loc+'&heading='+head+'&key=AIzaSyBJ3lOGp3I6dHreSC3NePYUfNUwjItoRbE'\n",
    "\n",
    "    r = requests.get(url)\n",
    "    results = r.json()\n",
    "\n",
    "    def check_status(request):\n",
    "        status = request['status']\n",
    "        if status == 'OK':\n",
    "            return r'https://maps.googleapis.com/maps/api/streetview?size=600x300&location='+loc+'&heading='+head+'&key=AIzaSyBJ3lOGp3I6dHreSC3NePYUfNUwjItoRbE'\n",
    "        else:\n",
    "            return find_image_paris()\n",
    "\n",
    "    return check_status(results)\n",
    "\n",
    "def get_image_data():\n",
    "    try:\n",
    "        URL = find_image_paris()\n",
    "        with urllib.request.urlopen(URL) as url:\n",
    "            f = io.BytesIO(url.read())\n",
    "    except:\n",
    "        return get_image_data()\n",
    "\n",
    "    img = Image.open(f)\n",
    "\n",
    "    pix = img.load()\n",
    "    a,b = img.size\n",
    "    pic = np.array([[pix[x,y] for x in range(a)] for y in range(b)])\n",
    "    return pic.astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lab(data):\n",
    "    return color.rgb2lab(data)\n",
    "\n",
    "def rgb(data):\n",
    "    return np.array([(color.lab2rgb(instance) * 255).round().astype(np.uint8) for instance in data])\n",
    "\n",
    "def L(data):\n",
    "    return data[:,:,:,0:1]\n",
    "\n",
    "def ab(data):\n",
    "    return data[:,:,:,1:]\n",
    "\n",
    "def fuse(L, ab):\n",
    "    return np.concatenate((L, ab),axis=3)\n",
    "\n",
    "def run_test():\n",
    "    test_rgb = [get_image_data() for i in range(5)]\n",
    "    test_lab = lab(test_rgb)\n",
    "    test_outputs_ab = output.eval(feed_dict={X: L(test_lab)})\n",
    "    test_outputs_lab = fuse(L(test_lab),test_outputs_ab)\n",
    "    test_outputs_rgb = rgb(test_outputs_lab)\n",
    "    print(test_lab[0])\n",
    "    print(test_outputs_lab[0])\n",
    "    for i in range(5):\n",
    "        plt.subplot(5, 2, i * 2 + 1)\n",
    "        plot_color_image((test_rgb[i] * 255).round().astype(np.uint8))\n",
    "        plt.subplot(5, 2, i * 2 + 2)\n",
    "        plot_color_image(test_outputs_rgb[i])\n",
    "    plt.show()\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image.astype(np.uint8),interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_color_image((get_image_data() * 255).round().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = 300\n",
    "width = 600\n",
    "channels = 2\n",
    "n_inputs = height * width\n",
    "\n",
    "conv0_fmaps = 16\n",
    "conv0_ksize = 55\n",
    "conv0_stride = 1\n",
    "conv0_pad = \"SAME\"\n",
    "\n",
    "conv1_fmaps = 16\n",
    "conv1_ksize = 21\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 32\n",
    "conv2_ksize = 9\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "conv3_fmaps = 32\n",
    "conv3_ksize = 3\n",
    "conv3_stride = 1\n",
    "conv3_pad = \"SAME\"\n",
    "\n",
    "conv4_fmaps = 64\n",
    "conv4_ksize = 1\n",
    "conv4_stride = 1\n",
    "conv4_pad = \"SAME\"\n",
    "\n",
    "dropout_rate = 0\n",
    "noise_level = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name ='training')\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape =[None, height, width, 1], name='X')\n",
    "    y = tf.placeholder(tf.float32, shape =[None, height, width, channels], name='y')\n",
    "    X_noisy = X + noise_level * tf.random_normal(tf.shape(X))\n",
    "    X_drop = tf.layers.dropout(X_noisy, dropout_rate, training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    batch_norm = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "\n",
    "    max_pool0 = tf.nn.max_pool(X_drop/255, ksize=[1,2,2,1], strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "    conv0 = tf.layers.conv2d(max_pool0, filters=conv0_fmaps, kernel_size=conv0_ksize,\\\n",
    "                             strides=conv0_stride, padding=conv0_pad, name=\"conv0\")\n",
    "    conv0_batch = batch_norm(conv0)\n",
    "    res0 = tf.nn.elu(conv0_batch)\n",
    "\n",
    "\n",
    "    conv1 = tf.layers.conv2d(res0, filters=conv1_fmaps, kernel_size=conv1_ksize,\\\n",
    "                             strides=conv1_stride, padding=conv1_pad, name=\"conv1\")\n",
    "    conv1_batch = batch_norm(conv1)\n",
    "    res1 = tf.nn.elu(conv1_batch)\n",
    "\n",
    "\n",
    "    conv2 = tf.layers.conv2d(res1, filters=conv2_fmaps, kernel_size=conv2_ksize,\\\n",
    "                             strides=conv2_stride, padding=conv2_pad, name=\"conv2\")\n",
    "    conv2_batch = batch_norm(conv2)\n",
    "    res2 = tf.nn.elu(conv2_batch)\n",
    "\n",
    "\n",
    "    conv3 = tf.layers.conv2d(res2, filters=conv3_fmaps, kernel_size=conv3_ksize,\\\n",
    "                             strides=conv3_stride, padding=conv3_pad, name=\"conv3\")\n",
    "    conv3_batch = batch_norm(conv3)\n",
    "    res3 = tf.nn.elu(conv3_batch)\n",
    "\n",
    "\n",
    "    conv4 = tf.layers.conv2d(res3, filters=conv4_fmaps, kernel_size=conv4_ksize,\\\n",
    "                             strides=conv4_stride, padding=conv4_pad, name=\"conv4\")\n",
    "    conv4_batch = batch_norm(conv4)\n",
    "    res4 = tf.nn.elu(conv4_batch)\n",
    "\n",
    "\n",
    "    res_input = tf.nn.elu(batch_norm(tf.layers.conv2d(res4, filters=4, kernel_size=3,\\\n",
    "                             strides=1, padding=\"SAME\", name=\"res_input\")))\n",
    "\n",
    "    output = tf.layers.conv2d_transpose(tf.nn.elu(batch_norm(res_input)), filters=2, kernel_size=1,\\\n",
    "                             strides=2, padding=\"SAME\", name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    with tf.name_scope(\"train\"):\n",
    "        loss = tf.reduce_sum(tf.square(output - y))\n",
    "        loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)\n",
    "\n",
    "logdir = log_dir(\"gmaps_cae\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "checkpoint_path = \"/tmp/gmaps_cae_model17.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./gmaps_cae_model17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "n_epochs = 1000\n",
    "best_loss = np.infty\n",
    "epochs_without_progress = 0\n",
    "max_epochs_without_progress = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "    run_test()\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        training_set = [get_image_data() for i in range(batch_size)]\n",
    "        training_set_lab = lab(training_set)\n",
    "        Xs = np.array(L(training_set_lab))\n",
    "        ys = np.array(ab(training_set_lab))\n",
    "        _, _, loss_val, loss_summary_str = sess.run([training_op, extra_update_ops, loss, loss_summary], feed_dict={X:Xs, y: ys, training: True})\n",
    "        file_writer.add_summary(loss_summary_str, epoch)\n",
    "        print(epoch, loss_val)\n",
    "        saver.save(sess, checkpoint_path)\n",
    "        with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "            f.write(b\"%d\" % (epoch + 1))\n",
    "        if loss_val < best_loss:\n",
    "            saver.save(sess, final_model_path)\n",
    "            best_loss = loss_val\n",
    "        else:\n",
    "            epochs_without_progress += 1\n",
    "            if epochs_without_progress > max_epochs_without_progress:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        if epoch % 10 == 11:\n",
    "            run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
